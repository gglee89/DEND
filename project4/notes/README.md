# About

Notes from the Data pipeline with Apache Airflow course.

# Data Pipelines

- A series of steps takes to process data
- Importance of **Data Validation** to prevent erroneous outputs

#### After loading from S3 to redshift

- Validate the number of rows in Redshift match the number of records in S3

#### Once location business analysis is complete

- Validate that all locations have a daily visit average greater than 0 (Any output data produced at all?)

#### DAGs (Directed Acyclic Graphs)

- Data Pipelines are expressed as such
-

# Author

**Giwoo G Lee**  
Data Engineer  
[linkedin](https://linkedin.com/in/leegiwoo)
